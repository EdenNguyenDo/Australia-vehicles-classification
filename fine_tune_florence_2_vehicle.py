# -*- coding: utf-8 -*-
"""fine-tune-florence-2-vehicle.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-GAqpF8VsjM8XkVO7DBA8GLpgXGJOwxj

## Setup
"""
from server import DEVICE
from train import train_model

# !pip install timm flash_attn einops;
# !pip install -q roboflow git+https://github.com/roboflow/supervision.git

"""Now we import the packages we'll need, including the `utils.py` module from the repository that we just cloned. 
This file provides misellaneous functionality to make it easier to work with Florence-2."""


import os
import json
import torch
from config import configLora
import numpy as np
import supervision as sv
from IPython.core.display import display, HTML
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AdamW,
    AutoModelForCausalLM,
    AutoProcessor,
    get_scheduler
)
from tqdm import tqdm
from typing import List, Dict, Any, Tuple, Generator
from peft import get_peft_model
from PIL import Image
from transformers import AutoProcessor, AutoModelForCausalLM
from PIL import Image
import utils
import torch
# %matplotlib inline

"""Next we load the Florence-2 model and processor"""

CHECKPOINT = "microsoft/Florence-2-large"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = AutoModelForCausalLM.from_pretrained(CHECKPOINT, trust_remote_code=True).to(DEVICE)
processor = AutoProcessor.from_pretrained(CHECKPOINT, trust_remote_code=True)

"""And then we set these models as constants for our `utils.py` module so that the functions can utilize them as global constants."""

utils.set_model_info(model, processor)

"""LOAD IMAGES"""

path = "dataset/train/frame2.png"
image = Image.open(path)
image_rgb = Image.open(path).convert("RGB")

"""#### Object detection

Object detection automatically detects the salient objects in an image. Florence-2 supports 3 levels of semantic granularity:
1. None (bounding boxes only)
2. Categorical labels
3. Descriptive labels
"""

tasks = [utils.TaskType.OBJECT_DETECTION]

for task in tasks:
  results = utils.run_example(task, image_rgb)
  print(task.value)
  utils.plot_bbox(results[task], image)

"""# FINE TUNING FLORENCE 2 AND TRAIN ON A CUSTOM DATASET"""





class JSONLDataset:
    """
    A dataset class for loading images and annotations from a JSONL file.

    Attributes:
        jsonl_file_path (str): Path to the JSONL file containing annotations.
        image_directory_path (str): Path to the directory containing images.
        entries (List[Dict[str, Any]]): Parsed list of annotation entries.
    """

    def __init__(self, jsonl_file_path: str, image_directory_path: str):
        """
        Initialize the dataset with a JSONL file and image directory.

        Args:
            jsonl_file_path (str): Path to the JSONL annotation file.
            image_directory_path (str): Path to the directory containing images.
        """
        self.jsonl_file_path = jsonl_file_path
        self.image_directory_path = image_directory_path
        self.entries = self._load_entries()

    def _load_entries(self) -> List[Dict[str, Any]]:
        """
        Parse the JSONL file to load annotation entries.

        Returns:
            List[Dict[str, Any]]: A list of parsed entries from the JSONL file.
        """
        entries = []
        with open(self.jsonl_file_path, 'r') as file:
            for line in file:
                data = json.loads(line)
                entries.append(data)
        return entries

    def __len__(self) -> int:
        """Return the number of entries in the dataset."""

        return len(self.entries)

    def __getitem__(self, idx: int) -> Tuple[Image.Image, Dict[str, Any]]:
        """
        Retrieve an image and its associated annotation.

        Args:
            idx (int): Index of the desired entry.

        Returns:
            Tuple[Image.Image, Dict[str, Any]]: The image and its annotation data.

        Raises:
            IndexError: If the index is out of range.
            FileNotFoundError: If the specified image file is not found.
        """
        if idx < 0 or idx >= len(self.entries):
            raise IndexError("Index out of range")

        entry = self.entries[idx]
        image_path = os.path.join(self.image_directory_path, entry['image'])
        try:
            image = Image.open(image_path)
            return (image, entry)
        except FileNotFoundError:
            raise FileNotFoundError(f"Image file {image_path} not found.")


class DetectionDataset(Dataset):
    """
    A PyTorch Dataset wrapper for handling detection datasets.

    Attributes:
        dataset (JSONLDataset): The underlying dataset object.
    """

    def __init__(self, jsonl_file_path: str, image_directory_path: str):
        """
        Initialize the detection dataset using a JSONL file and image directory.

        Args:
            jsonl_file_path (str): Path to the JSONL annotation file.
            image_directory_path (str): Path to the directory containing images.
        """
        self.dataset = JSONLDataset(jsonl_file_path, image_directory_path)

    def __len__(self):
        """Return the number of entries in the dataset."""
        return len(self.dataset)

    def __getitem__(self, idx):
        """
        Retrieve a dataset entry consisting of prefix, suffix, and image.

        Args:
            idx (int): Index of the desired entry.

        Returns:
            Tuple[str, str, Image.Image]: Prefix, suffix, and the associated image.
        """
        image, data = self.dataset[idx]
        prefix = data['prefix']
        suffix = data['suffix']
        return prefix, suffix, image

# @title Initiate `DetectionsDataset` and `DataLoader` for train and validation subsets

BATCH_SIZE = 6
NUM_WORKERS = 0

def collate_fn(batch):
    questions, answers, images = zip(*batch)
    images = [image.convert('RGB') for image in images]
    inputs = processor(text=list(questions), images=list(images), return_tensors="pt", padding=True).to(DEVICE)
    return inputs, answers

train_dataset = DetectionDataset(
    jsonl_file_path = "dataset/train/annotation.jsonl",
    image_directory_path = "dataset/train/"
)
val_dataset = DetectionDataset(
    jsonl_file_path = "dataset/valid/annotation.jsonl",
    image_directory_path = "dataset/valid/"
)

"""
Configure train loader and validation loader
"""
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=NUM_WORKERS, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=NUM_WORKERS)



"""### Setup LoRA Florence-2 model

LoRA is low-rank decomposition method to reduce the number of trainable parameters which speeds up finetuning large models and uses less memory.
"""
peft_model = get_peft_model(model, configLora())
peft_model.print_trainable_parameters()


# @title Define train loop
EPOCHS = 17
LR = 5e-6
# 
train_model(train_loader, val_loader, peft_model, processor, epochs=EPOCHS, lr=LR)


"""### Save the model"""

peft_model.save_pretrained("saved_model/ft-florence2-LORA")
processor.save_pretrained("saved_model/ft-florence2-LORA")

